{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_CheckInputs' from partially initialized module 'tsi_toolkit._check_inputs' (most likely due to a circular import) (/home/clewin/projects/tsi-toolkit/tsi_toolkit/_check_inputs.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsi_toolkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/tsi-toolkit/tsi_toolkit/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoherence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Coherence\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_spectrum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossSpectrum\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightCurve\n",
      "File \u001b[0;32m~/projects/tsi-toolkit/tsi_toolkit/coherence.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_check_inputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _CheckInputs\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpower_spectrum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PowerSpectrum\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_spectrum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossSpectrum\n",
      "File \u001b[0;32m~/projects/tsi-toolkit/tsi_toolkit/_check_inputs.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightCurve\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaussian_process\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianProcess\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_CheckInputs\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/tsi-toolkit/tsi_toolkit/data_loader.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mastropy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fits\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Plotter\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_check_inputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _CheckInputs\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLightCurve\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     11\u001b[0m                  times\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     12\u001b[0m                  rates\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m                  ):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# To do: Improve commenting and docstrings, use _check_inputs\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_CheckInputs' from partially initialized module 'tsi_toolkit._check_inputs' (most likely due to a circular import) (/home/clewin/projects/tsi-toolkit/tsi_toolkit/_check_inputs.py)"
     ]
    }
   ],
   "source": [
    "from tsi_toolkit import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_light_curve(\n",
    "    n_points,  # Total duration of the time series (in arbitrary units, e.g., seconds or days)\n",
    "    sampling_interval,  # Sampling interval for the time series\n",
    "    alpha=2.0,  # Slope of the red noise PSD (alpha = 1 corresponds to 1/f noise)\n",
    "    random_seed=None  # Optional seed for reproducibility\n",
    "):\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    time = np.linspace(0, n_points*sampling_interval, n_points)\n",
    "    dt = time[1] - time[0]\n",
    "    freqs = np.fft.rfftfreq(n_points, d=dt)\n",
    "    \n",
    "    # Define the red noise PSD: P(f) propto 1 / f^alpha\n",
    "    psd = 1 / (freqs + 1e-5) ** alpha  # Avoid division by zero\n",
    "    \n",
    "    random_phases = np.exp(2j * np.pi * np.random.rand(len(freqs)))\n",
    "    amplitudes = np.sqrt(psd)\n",
    "    fourier_coeffs = amplitudes * random_phases\n",
    "    \n",
    "    red_noise = np.fft.irfft(fourier_coeffs, n=n_points)\n",
    "\n",
    "    red_noise = 10 * red_noise / np.std(red_noise)\n",
    "    red_noise = red_noise - np.mean(red_noise) + 100\n",
    "\n",
    "    # introduce white noise\n",
    "    counts = red_noise * dt\n",
    "    flux = np.random.normal(loc=counts, scale=np.sqrt(counts))\n",
    "    flux = flux / dt\n",
    "    fluxerrors = np.sqrt(flux)\n",
    "    #flux = red_noise\n",
    "    fft = np.fft.rfft(flux)\n",
    "    power_spectrum = np.abs(fft) ** 2\n",
    "\n",
    "    freq_mask = (freqs >= 1e-8) & (freqs <= 1/(2 * dt))\n",
    "    freqs = freqs[freq_mask]\n",
    "    power_spectrum = power_spectrum[freq_mask]\n",
    "    fft = fft[freq_mask]\n",
    "    \n",
    "    return time, flux, fluxerrors, freqs, fft, power_spectrum\n",
    "\n",
    "# Example usage\n",
    "n_points = 1000\n",
    "sampling_interval = 1\n",
    "time, light_curve, light_curve_errors, freqs, fft, power_spectrum = simulate_light_curve(\n",
    "    n_points=n_points, \n",
    "    sampling_interval=sampling_interval, \n",
    "    alpha=2, \n",
    "    random_seed=40\n",
    ")\n",
    "\n",
    "time2, light_curve2, light_curve_errors2, freqs2, fft2, power_spectrum2 = simulate_light_curve(\n",
    "    n_points=n_points,\n",
    "    sampling_interval=sampling_interval, \n",
    "    alpha=1, \n",
    "    random_seed=43\n",
    ")\n",
    "lightcurve_object1 = LightCurve(time, light_curve, light_curve_errors)\n",
    "lightcurve_object1.plot()\n",
    "lightcurve_object2 = LightCurve(time2, light_curve2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test object imports\n",
    "# verify psd\n",
    "power_spectrum_tsi = PowerSpectrum(lightcurve=lightcurve_object1, norm=False)\n",
    "\n",
    "# Check if power_spectrum_tsi.powers agrees with power_spectrum\n",
    "assert np.allclose(power_spectrum_tsi.freqs, freqs), \"The frequencies do not match!\"\n",
    "assert np.allclose(power_spectrum_tsi.powers, power_spectrum), \"The power spectra do not match!\"\n",
    "\n",
    "# verify cross spectrum\n",
    "true_cross_spectrum = np.conj(fft) * fft2\n",
    "cross_spectrum_tsi = CrossSpectrum(lightcurve1=lightcurve_object1, lightcurve2=lightcurve_object2, norm=False)\n",
    "\n",
    "# Check if cross_spectrum_tsi.cs agrees with true_cross_spectrum\n",
    "assert np.allclose(cross_spectrum_tsi.cs, true_cross_spectrum), \"The cross spectra do not match!\"\n",
    "# verify lag frequency spectrum\n",
    "true_lag_spectrum = np.angle(true_cross_spectrum) / (2 * np.pi * freqs)\n",
    "lag_spectrum_tsi = LagFrequencySpectrum(\n",
    "    lightcurve1=lightcurve_object1, lightcurve2=lightcurve_object2, subtract_coh_bias=False\n",
    "    )\n",
    "\n",
    "# Check if lag_spectrum_tsi.lags agrees with true_lag_spectrum\n",
    "assert np.allclose(lag_spectrum_tsi.lags, true_lag_spectrum), \"The lag spectra do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test GP noise homoskedastic noise\n",
    "lightcurve_object1 = LightCurve(time, light_curve)\n",
    "power_spectrum_tsi = PowerSpectrum(lightcurve=lightcurve_object1, norm=True)\n",
    "plt.scatter(power_spectrum_tsi.freqs, power_spectrum_tsi.powers, s=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# light_curve_adj = light_curve / np.std(light_curve)\n",
    "# light_curve_adj = light_curve_adj - np.mean(light_curve_adj)\n",
    "# print(np.mean(np.abs(light_curve_adj)))\n",
    "# lightcurve_object1 = lightcurve(time, light_curve_adj)\n",
    "# power_spectrum_tsi = PowerSpectrum(lightcurve=lightcurve_object1, norm=False)\n",
    "# plt.scatter(power_spectrum_tsi.freqs, power_spectrum_tsi.powers, s=2)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.show()\n",
    "\n",
    "# mean_error1 = np.mean(np.sqrt(light_curve_adj))\n",
    "# mean1 = np.mean(light_curve_adj)\n",
    "# nyquist_freq = 1 / (2 * (time[1] - time[0]))\n",
    "# pnoise1 = mean_error1 ** 2 / ( nyquist_freq * mean1 ** 2 )\n",
    "# print(pnoise1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylag import GPLightCurve\n",
    "gp_pylag = GPLightCurve(t=time, r=light_curve,\n",
    "                        kernel='matern12',\n",
    "                        lognorm=False, noise_kernel=True, \n",
    "                        run_fit=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values = gp_pylag.get_fit_param(log_par=False)\n",
    "params = gp_pylag.make_param_dict(param_values, log_par=False)\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing noise implementation (with and without error inputs)\n",
    "lightcurve_object1 = LightCurve(time, light_curve)\n",
    "gp_model = GaussianProcess(lightcurve=lightcurve_object1,\n",
    "                           kernel_form='Matern12', white_noise=True, \n",
    "                           num_iter=10, learn_rate=1e-1,\n",
    "                           verbose=False)\n",
    "gp_model.plot()\n",
    "lightcurve_object1 = LightCurve(time, light_curve, light_curve_errors)\n",
    "\n",
    "gp_model = GaussianProcess(lightcurve=lightcurve_object1,\n",
    "                           kernel_form='Matern12', white_noise=True, \n",
    "                           num_iter=10, learn_rate=1e-1,\n",
    "                           verbose=False)\n",
    "\n",
    "plt.scatter(gp_model.train_times, gp_model.train_rates, s=2)\n",
    "plt.show()\n",
    "gp_model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PowerSpectrum(model=gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "def bic(lml, num_params, num_data):\n",
    "    return -2 * lml + num_params * np.log(num_data)\n",
    "\n",
    "def train_gp_model(train_x, train_y, kernel, lr = 0.01, training_iter = 2000, verbal = False):\n",
    "    \n",
    "    def create_gp_model(train_x, train_y, likelihood, kernel):\n",
    "        class GPModel(gpytorch.models.ExactGP):\n",
    "            def __init__(self, train_x, train_y, likelihood):\n",
    "                super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
    "                self.mean_module = gpytorch.means.ZeroMean()\n",
    "                if kernel == 'Matern12':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5))\n",
    "                elif kernel == 'Matern32':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5))\n",
    "                elif kernel == 'Matern52':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5))\n",
    "                elif kernel == 'RQ':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RQKernel())\n",
    "                elif kernel == 'RBF':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "                else:\n",
    "                    raise(ValueError('Invalid kernel type'))\n",
    "\n",
    "            def forward(self, x):\n",
    "                mean_x = self.mean_module(x)\n",
    "                covar_x = self.covar_module(x)\n",
    "                return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "        return GPModel(train_x, train_y, likelihood)\n",
    "\n",
    "    # initialize likelihood and model\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "        learn_additional_noise=True,\n",
    "        noise_prior=gpytorch.priors.NormalPrior(0.1, 0.5), \n",
    "    )\n",
    "\n",
    "    # create gp model\n",
    "    model = create_gp_model(train_x, train_y, likelihood, kernel)\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "\n",
    "        if verbal:\n",
    "                print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    model.covar_module.base_kernel.lengthscale.item(),\n",
    "                    model.likelihood.noise.item()\n",
    "                ))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    num_params = sum([p.numel() for p in model.parameters()])\n",
    "    inf_crit = bic(-loss.item(), num_params, len(train_x))\n",
    "    \n",
    "    return model, likelihood, inf_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "light_curve_standardized = (light_curve - np.mean(light_curve)) / np.std(light_curve)\n",
    "plt.scatter(time, light_curve_standardized, s=2)\n",
    "plt.show()\n",
    "\n",
    "train_x = torch.tensor(time).float()\n",
    "train_y = torch.tensor(light_curve_standardized).float()\n",
    "\n",
    "# kernel comparison using bayesian information criterion\n",
    "model, likelihood, inf_crit = train_gp_model(train_x, train_y, \n",
    "                                             'Matern12', lr = 1e-1,\n",
    "                                             verbal = True)\n",
    "\n",
    "print('Model hypers: ', model.covar_module.base_kernel.lengthscale.item(), model.likelihood.noise.item())\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
