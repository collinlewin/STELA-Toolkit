{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsi_toolkit import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_time_series(\n",
    "    n_points,  # Total duration of the time series (in arbitrary units, e.g., seconds or days)\n",
    "    sampling_interval,  # Sampling interval for the time series\n",
    "    alpha=2.0,  # Slope of the red noise PSD (alpha = 1 corresponds to 1/f noise)\n",
    "    random_seed=None  # Optional seed for reproducibility\n",
    "):\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    time = np.linspace(0, n_points*sampling_interval, n_points)\n",
    "    dt = time[1] - time[0]\n",
    "    freqs = np.fft.rfftfreq(n_points, d=dt)\n",
    "    \n",
    "    # Define the red noise PSD: P(f) propto 1 / f^alpha\n",
    "    psd = 1 / (freqs + 1e-5) ** alpha  # Avoid division by zero\n",
    "    \n",
    "    random_phases = np.exp(2j * np.pi * np.random.rand(len(freqs)))\n",
    "    amplitudes = np.sqrt(psd)\n",
    "    fourier_coeffs = amplitudes * random_phases\n",
    "    \n",
    "    red_noise = np.fft.irfft(fourier_coeffs, n=n_points)\n",
    "\n",
    "    red_noise = 10 * red_noise / np.std(red_noise)\n",
    "    red_noise = red_noise - np.mean(red_noise) + 100\n",
    "\n",
    "    # introduce white noise\n",
    "    #counts = red_noise * dt\n",
    "    #flux = np.random.normal(loc=counts, scale=np.sqrt(counts))\n",
    "    #flux = flux / dt\n",
    "    #fluxsigmas = np.sqrt(flux)\n",
    "    flux = red_noise\n",
    "    fft = np.fft.rfft(flux)\n",
    "    power_spectrum = np.abs(fft) ** 2\n",
    "\n",
    "    freq_mask = (freqs >= 1e-8) & (freqs <= 1/(2 * dt))\n",
    "    freqs = freqs[freq_mask]\n",
    "    power_spectrum = power_spectrum[freq_mask]\n",
    "    fft = fft[freq_mask]\n",
    "\n",
    "    fluxsigmas = None\n",
    "    \n",
    "    return time, flux, fluxsigmas, freqs, fft, power_spectrum\n",
    "\n",
    "# Example usage\n",
    "n_points = 1000\n",
    "sampling_interval = 1\n",
    "time, time_series, time_series_sigmas, freqs, fft, power_spectrum = simulate_time_series(\n",
    "    n_points=n_points, \n",
    "    sampling_interval=sampling_interval, \n",
    "    alpha=2, \n",
    "    random_seed=40\n",
    ")\n",
    "\n",
    "time2, time_series2, time_series_sigmas2, freqs2, fft2, power_spectrum2 = simulate_time_series(\n",
    "    n_points=n_points,\n",
    "    sampling_interval=sampling_interval, \n",
    "    alpha=1, \n",
    "    random_seed=43\n",
    ")\n",
    "\n",
    "timeseries_object1 = TimeSeries(time, time_series)\n",
    "timeseries_object1.plot()\n",
    "timeseries_object2 = TimeSeries(time2, time_series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test array imports\n",
    "# verify psd\n",
    "power_spectrum_tsi = PowerSpectrum(times=time, values=time_series, norm=False)\n",
    "\n",
    "# Check if power_spectrum_tsi.powers agrees with power_spectrum\n",
    "assert np.allclose(power_spectrum_tsi.freqs, freqs), \"The frequencies do not match!\"\n",
    "assert np.allclose(power_spectrum_tsi.powers, power_spectrum), \"The power spectra do not match!\"\n",
    "\n",
    "# verify cross spectrum\n",
    "true_cross_spectrum = np.conj(fft) * fft2\n",
    "cross_spectrum_tsi = CrossSpectrum(times1=time, values1=time_series, times2=time2, values2=time_series2, norm=False)\n",
    "\n",
    "# Check if cross_spectrum_tsi.cs agrees with true_cross_spectrum\n",
    "assert np.allclose(cross_spectrum_tsi.cs, true_cross_spectrum), \"The cross spectra do not match!\"\n",
    "# verify lag frequency spectrum\n",
    "true_lag_spectrum = np.angle(true_cross_spectrum) / (2 * np.pi * freqs)\n",
    "lag_spectrum_tsi = LagFrequencySpectrum(\n",
    "    times1=time, values1=time_series, times2=time2, values2=time_series2, subtract_coh_bias=False\n",
    "    )\n",
    "\n",
    "# Check if lag_spectrum_tsi.lags agrees with true_lag_spectrum\n",
    "assert np.allclose(lag_spectrum_tsi.lags, true_lag_spectrum), \"The lag spectra do not match!\"\n",
    "\n",
    "\n",
    "\n",
    "### test object imports\n",
    "# verify psd\n",
    "power_spectrum_tsi = PowerSpectrum(timeseries=timeseries_object1, norm=False)\n",
    "\n",
    "# Check if power_spectrum_tsi.powers agrees with power_spectrum\n",
    "assert np.allclose(power_spectrum_tsi.freqs, freqs), \"The frequencies do not match!\"\n",
    "assert np.allclose(power_spectrum_tsi.powers, power_spectrum), \"The power spectra do not match!\"\n",
    "\n",
    "# verify cross spectrum\n",
    "true_cross_spectrum = np.conj(fft) * fft2\n",
    "cross_spectrum_tsi = CrossSpectrum(timeseries1=timeseries_object1, timeseries2=timeseries_object2, norm=False)\n",
    "\n",
    "# Check if cross_spectrum_tsi.cs agrees with true_cross_spectrum\n",
    "assert np.allclose(cross_spectrum_tsi.cs, true_cross_spectrum), \"The cross spectra do not match!\"\n",
    "# verify lag frequency spectrum\n",
    "true_lag_spectrum = np.angle(true_cross_spectrum) / (2 * np.pi * freqs)\n",
    "lag_spectrum_tsi = LagFrequencySpectrum(\n",
    "    timeseries1=timeseries_object1, timeseries2=timeseries_object2, subtract_coh_bias=False\n",
    "    )\n",
    "\n",
    "# Check if lag_spectrum_tsi.lags agrees with true_lag_spectrum\n",
    "assert np.allclose(lag_spectrum_tsi.lags, true_lag_spectrum), \"The lag spectra do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test GP noise homoskedastic noise\n",
    "timeseries_object1 = TimeSeries(time, time_series)\n",
    "power_spectrum_tsi = PowerSpectrum(timeseries=timeseries_object1, norm=True)\n",
    "plt.scatter(power_spectrum_tsi.freqs, power_spectrum_tsi.powers, s=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# time_series_adj = time_series / np.std(time_series)\n",
    "# time_series_adj = time_series_adj - np.mean(time_series_adj)\n",
    "# print(np.mean(np.abs(time_series_adj)))\n",
    "# timeseries_object1 = TimeSeries(time, time_series_adj)\n",
    "# power_spectrum_tsi = PowerSpectrum(timeseries=timeseries_object1, norm=False)\n",
    "# plt.scatter(power_spectrum_tsi.freqs, power_spectrum_tsi.powers, s=2)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.show()\n",
    "\n",
    "# mean_sigma1 = np.mean(np.sqrt(time_series_adj))\n",
    "# mean1 = np.mean(time_series_adj)\n",
    "# nyquist_freq = 1 / (2 * (time[1] - time[0]))\n",
    "# pnoise1 = mean_sigma1 ** 2 / ( nyquist_freq * mean1 ** 2 )\n",
    "# print(pnoise1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylag import GPLightCurve\n",
    "gp_pylag = GPLightCurve(t=time, r=time_series,\n",
    "                        kernel='matern12',\n",
    "                        lognorm=False, noise_kernel=True, \n",
    "                        run_fit=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values = gp_pylag.get_fit_param(log_par=False)\n",
    "params = gp_pylag.make_param_dict(param_values, log_par=False)\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_object1 = TimeSeries(time, time_series)\n",
    "gp_model = GaussianProcess(timeseries=timeseries_object1,\n",
    "                           kernel_form='Matern12', white_noise=True, \n",
    "                           train_iter=1000, learn_rate=1e-0,\n",
    "                             verbose=True)\n",
    "\n",
    "plt.scatter(gp_model.train_times, gp_model.train_values, s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "def bic(lml, num_params, num_data):\n",
    "    return -2 * lml + num_params * np.log(num_data)\n",
    "\n",
    "def train_gp_model(train_x, train_y, kernel, lr = 0.01, training_iter = 2000, verbal = False):\n",
    "    \n",
    "    def create_gp_model(train_x, train_y, likelihood, kernel):\n",
    "        class GPModel(gpytorch.models.ExactGP):\n",
    "            def __init__(self, train_x, train_y, likelihood):\n",
    "                super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
    "                self.mean_module = gpytorch.means.ZeroMean()\n",
    "                if kernel == 'Matern12':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5))\n",
    "                elif kernel == 'Matern32':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5))\n",
    "                elif kernel == 'Matern52':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5))\n",
    "                elif kernel == 'RQ':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RQKernel())\n",
    "                elif kernel == 'RBF':\n",
    "                    self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "                else:\n",
    "                    raise(ValueError('Invalid kernel type'))\n",
    "\n",
    "            def forward(self, x):\n",
    "                mean_x = self.mean_module(x)\n",
    "                covar_x = self.covar_module(x)\n",
    "                return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "        return GPModel(train_x, train_y, likelihood)\n",
    "\n",
    "    # initialize likelihood and model\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "        learn_additional_noise=True,\n",
    "        noise_prior=gpytorch.priors.NormalPrior(0.1, 0.5), \n",
    "    )\n",
    "\n",
    "    # create gp model\n",
    "    model = create_gp_model(train_x, train_y, likelihood, kernel)\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "\n",
    "        if verbal:\n",
    "                print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    model.covar_module.base_kernel.lengthscale.item(),\n",
    "                    model.likelihood.noise.item()\n",
    "                ))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    num_params = sum([p.numel() for p in model.parameters()])\n",
    "    inf_crit = bic(-loss.item(), num_params, len(train_x))\n",
    "    \n",
    "    return model, likelihood, inf_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "time_series_standardized = (time_series - np.mean(time_series)) / np.std(time_series)\n",
    "plt.scatter(time, time_series_standardized, s=2)\n",
    "plt.show()\n",
    "\n",
    "train_x = torch.tensor(time).float()\n",
    "train_y = torch.tensor(time_series_standardized).float()\n",
    "\n",
    "# kernel comparison using bayesian information criterion\n",
    "model, likelihood, inf_crit = train_gp_model(train_x, train_y, \n",
    "                                             'Matern12', lr = 1e1,\n",
    "                                             verbal = True)\n",
    "\n",
    "print('Model hypers: ', model.covar_module.base_kernel.lengthscale.item(), model.likelihood.noise.item())\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
